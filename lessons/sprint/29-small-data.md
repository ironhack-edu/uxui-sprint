<!-- ![Ironhack logo](https://i.imgur.com/1QgrNNw.png) -->

<!-- # "Small Data" and How to User Test -->

## Learning Goals

- Understand why user research data is typically qualitative
- Understand why interviewing more users is not always better
- Understand the basics of running a user test

## Small Data

The tension between qualitative and quantitative research methods within social sciences is one every user researcher struggles with. "Small data" as used by Jake Knapp in _Sprint_ refers to the fewer data points that are collected through qualitative methods.

:::danger
"Small Data" can also refer to a narrow set of data points defined by a few attributes. i.e. small data in healthcare might be my own chart data or a subset of my chart data, whereas big data would refer to the data found within thousands of people's charts.
:::

When it comes to improving products, data--qualitative or quantitative--is almost always worth gathering. The type of data that should be collected and the right collection method that should be conducted should be determined by the goals of the research phase in question.

![](http://www.technosoftcorp.com/images/bg-insights.jpg)

**What's more important right now... insights or statistics?**

Jakob Nielsen argues that user researchers primarily focus on insights and therefore qualitative data and methods. Running an analysis on their own research consultations, the Nielsen-Norman group found that 5 users was the optimal number to uncover user trends. In their published findings, you can see a _small_ correlation between more users and more findings. Moral of the story? Yes, it is possible to interview too many people (at least from a practical standpoint).

![](https://media.nngroup.com/media/editor/alertbox/usability-problems-by-users-tested.png)

:::warning
See? Talking to more users lead to more findings, but not that many more.
:::

It is worth noting that Nielsen does point out some exceptions:

> - Quantitative studies (aiming at statistics, not insights): Test at least 20 users to get statistically significant numbers; tight confidence intervals require even more users.
> - Card sorting: Test at least 15 users per user group.
> - Eyetracking: Test 39 users if you want stable heatmaps.
>   -- Jakob Nielsen, [How many test users in a usability study](https://www.nngroup.com/articles/how-many-test-users/)

## Insights over Accuracy:

![](http://www.dnasoftware.com/wp-content/uploads/2015/07/targets.png)

> Better to accept a wider margin of error in usability metrics than to spend the entire budget learning too few things with extreme precision.
> -- Jakob Nielsen, [Accuracy vs. Insights in Quantitative Usability](https://www.nngroup.com/articles/accuracy-vs-insights-quantitative-ux/)

IRB-approved research is governed by standards and conventions that emphasize accuracy over anything else. The rise of lean product development affords us more opportunities to use less-accurate data, but more quickly. This doesn't mean gathering good data is unimportant, it just means we don't have to worry about statistical significance.

Lucky for us, user research doesn't happen in a vacuum, nor is it like pharmaceutical research, which takes years before it's validated by the market. Digital product user research develops theories about user behaviors that are often proven by the market within months. But unlike our genes, user behaviors change, and quickly.

Product professionals generally know that product roadmaps--a soft timeline of future product feature releases--rely on a consistent in-stream of user data about the current product and industry trends. A lot of this comes in the form of market research and click-metrics, but there is no substitute for 1-on-1 user interviews. After all, click-metrics tell you what users are clicking on, while interviews will tell you why.

## How to User Test

For this sprint, we'll be focusing on the interview-style of user testing. This type of user testing is a basic tool in any researcher or designer's toolbox, so here we'll cover some of the basics.

:::warning
Your first interview may feel unnatural or awkward. That's okay! It won't be long before yo start feeling excited about jumping into your next interview.
:::

![](http://shiftone.co.za/shiftone/wp-content/uploads/2016/01/user-testing.jpg)

### The Five-Act Interview

We'll be focusing on the "five-act interview", which was outlined by Michael Margolis, a research partner at GV.

You were already introduced to the components of the five-act interview yesterday, but here's a reminder:

**Act I**
A friendly welcome to start the interview

**Act II**
A series of general, open-ended context questions about the customer

**Act III**
Introduction to the prototype(s)

**Act IV**
Detailed tasks to get the customer reacting to the prototype

**Act V**
A quick debrief to capture the customerâ€™s overarching thoughts and impressions

### Some tips

1. **Set the tone.** Your first goal is to help the tester feel comfortable in the space. Comfort leads to honesty. Honesty leads to good data. Good data leads to insights.
2. **Set the agenda.** Give your tester a sense of what to expect and always give the tester an opportunity to back out.
3. **Ask for permission.** Your testers are doing you a favor by testing your prototypes, so ask them if they'd be willing to help out.
4. **Promote discovery.** Your testers are more likely to be engaged if they figure things out on their own. Just tell them where you'd like them to end up, don't navigate their route.
5. **Ask what and why?** Watching someone walk through a task is useless if you don't get their thoughts along the way. Use probing questions like "What do you expect that will do?" to pair actions with corresponding thoughts.
6. **Ask open-ended questions.** Don't present choices in your questions (yes/no).
7. **Be an objective observer.** Leave your assumptions, expectations, and dreams at the door.

![](https://www.justsell.com/wp-content/themes/justsell/resources/images/in-post/engaging-headers/top-30-open-ended-questions-570x375.png)

## Summary

- Small data in the GV Sprint refers to the fewer data points that we'll be collected in this sprint. Small data also refers to a limited scope of data points defined by a user or specific attributes.
- 5 user tests is optimal if your goal is to get insights, not statistics.
- Successful interviews rely on building good rapport and open-ended questions.

## Additional Resources

- [Michael Margolis conducts a five-act interview](https://www.youtube.com/watch?v=U9ZG19XTbd4)
- [Open-ended questions vs closed-ended questions in user research](https://www.nngroup.com/articles/open-ended-questions/)
